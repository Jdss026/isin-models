{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.sparse as sp\n",
        "from scipy.sparse import lil_matrix\n",
        "import torch\n",
        "from paramets import *\n",
        "# import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# import numpy as np\n",
        "from scipy.sparse import lil_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKMP6BShVEP6"
      },
      "source": [
        "## Rewrite the original code using torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UTrVkbBKT7_5"
      },
      "outputs": [],
      "source": [
        "# Ng, Tf = 64, 10001\n",
        "\n",
        "def laplacian(n):\n",
        "    # Total number of grid points\n",
        "    total_points = n * n\n",
        "\n",
        "    matrix_laplacian = lil_matrix((total_points, total_points))\n",
        "    \n",
        "    # Fill the matrix based on finite difference method for Laplacian\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            row = i * n + j  # Current grid point\n",
        "            \n",
        "            # Diagonal element\n",
        "            matrix_laplacian[row, row] = 4\n",
        "            \n",
        "            # Check and update neighbors (left, right, up, down)\n",
        "            if i > 0:\n",
        "                matrix_laplacian[row, (i - 1) * n + j] = -1  # Up\n",
        "            if i < n - 1:\n",
        "                matrix_laplacian[row, (i + 1) * n + j] = -1  # Down\n",
        "            if j > 0:\n",
        "                matrix_laplacian[row, i * n + (j - 1)] = -1  # Left\n",
        "            if j < n - 1:\n",
        "                matrix_laplacian[row, i * n + (j + 1)] = -1  # Right\n",
        "    \n",
        "    # Convert to CSR format for efficient arithmetic operations\n",
        "    \n",
        "    matrix_laplacian = matrix_laplacian.tocsr()\n",
        "    matrix_laplacian = -matrix_laplacian\n",
        "\n",
        "    # Extract coordinates and values\n",
        "    row_indices = []\n",
        "    col_indices = []\n",
        "    values = []\n",
        "\n",
        "    for row in range(matrix_laplacian.shape[0]):\n",
        "        start = matrix_laplacian.indptr[row]\n",
        "        end = matrix_laplacian.indptr[row + 1]\n",
        "        row_indices.extend([row] * (end - start))\n",
        "        col_indices.extend(matrix_laplacian.indices[start:end])\n",
        "        values.extend(matrix_laplacian.data[start:end])\n",
        "    \n",
        "    # convert to coo_matrix\n",
        "    coo_matrix = torch.sparse_coo_tensor(\n",
        "                torch.tensor([row_indices, col_indices], dtype=torch.int64),\n",
        "                torch.tensor(values, dtype=torch.float32),\n",
        "                torch.Size((n*n,n*n))\n",
        "                )\n",
        "    return coo_matrix\n",
        "\n",
        "master_list = []\n",
        "def integrate(L, u, T):\n",
        "    '''  simulates the equation and plots it at different instants '''\n",
        "    T = torch.tensor([T], device='cpu')\n",
        "    for i in range(Tf.item()):\n",
        "        noise = torch.normal(mean=0.0, std=1.0, size=(Ng * Ng, 1), device='cpu')\n",
        "        u = u - dt * (a * u + b * u * u * u - k * torch.mm(L, u)) + torch.sqrt(2 * T * dt) * noise  # Euler's method\n",
        "        if (i==10000):\n",
        "            master_list.append(u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate the mean of configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avg_realizations(master_list, Ng):\n",
        "    \"\"\" Evaluate the average over the configurations (realizations)\"\"\"\n",
        "    mean_config = []\n",
        "    size = len(master_list)\n",
        "    N = Ng*Ng\n",
        "    temp = 0\n",
        "    for point in tqdm(range(N), desc=\"Processing\", ncols=100, ascii=True):\n",
        "        for config in range(size):\n",
        "            temp += master_list[config][point]\n",
        "        mean_config.append(temp/size)\n",
        "        temp = 0\n",
        "    mean_config = torch.tensor(mean_config)\n",
        "    mean_config = mean_config.view((Ng, Ng))\n",
        "    return mean_config\n",
        "\n",
        "# mean_config = avg_realizations(master_list, Ng)\n",
        "# plt.imshow(mean_config)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avg_final(mean_config, Ng):\n",
        "    sum = 0 \n",
        "    for x in range(Ng):\n",
        "        for y in range(Ng):\n",
        "            sum = sum + mean_config[x][y]\n",
        "    return sum / (Ng*Ng)\n",
        "\n",
        "# media_final(mean_config, Ng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RUN PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CarlissonMiller\\Documents\\CloneGit\\ising-models\\venv\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Processing:   2%|#                                                   | 1/50 [00:09<07:57,  9.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  12%|######2                                             | 6/50 [01:00<07:19, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  22%|###########2                                       | 11/50 [01:43<05:29,  8.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  32%|################3                                  | 16/50 [02:24<04:42,  8.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  42%|#####################4                             | 21/50 [03:10<04:17,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  52%|##########################5                        | 26/50 [03:52<03:25,  8.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  62%|###############################6                   | 31/50 [04:35<02:40,  8.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  72%|####################################7              | 36/50 [05:16<01:54,  8.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  82%|#########################################8         | 41/50 [06:01<01:19,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  92%|##############################################9    | 46/50 [06:50<00:40, 10.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realization: 45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|###################################################| 50/50 [07:38<00:00,  9.17s/it]\n",
            "Processing: 100%|#############################################| 4096/4096 [00:02<00:00, 1913.55it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(-0.0136)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate the grid and initialise the field\n",
        "\n",
        "## define o dispositivo cuda a ser utilizado\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "x = torch.linspace(-1, 1, Ng)\n",
        "y = torch.linspace(-1, 1, Ng)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "\n",
        "## simula 100 configurações finais com os parametros iniciais\n",
        "L = laplacian(Ng)\n",
        "L = L.to(device)         # construct the laplacian\n",
        "N_real = 50\n",
        "\n",
        "list_vev = []\n",
        "for T in [0.1, 0.2, 0.3, 0.4]:\n",
        "  for realization in tqdm(range(N_real), desc=\"Processing\", ncols=100, ascii=True):\n",
        "    u = torch.randn(Ng * Ng, 1, device=device)  # Initial data\n",
        "    integrate(L, u, T)    # simulate\n",
        "    if realization % 10 ==0:\n",
        "      print(f'Realization: {realization}')\n",
        "\n",
        "  mean_config = avg_realizations(master_list, Ng)\n",
        "  VEV = avg_final(mean_config, Ng)\n",
        "  list_vev.append(VEV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
